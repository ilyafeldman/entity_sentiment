{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from simple_nlp import get_entities\n",
    "import sqlite3\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import contractions\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('news.db')\n",
    "df = pd.read_sql_query(\"SELECT title , date , text FROM kaggle_news\", connection)\n",
    "df = df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun(lines):\n",
    "\ttokenized = nltk.word_tokenize(lines)\n",
    "\tnouns = set([word for (word, pos) in nltk.pos_tag(tokenized) if(pos[:2] == 'NN')])\n",
    "\treturn nouns\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    #remove emails\n",
    "    text = re.sub(r'\\S*@\\S*\\s?',' ',text)\n",
    "    #remove mentions\n",
    "    text = re.sub(r'@\\S+', ' ', text)\n",
    "    #contractions\n",
    "    text = contractions.fix(text)\n",
    "    #remove hashtags\n",
    "    text = re.sub(r'@\\S+', ' ', text)\n",
    "    #remove emojis\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    #remove all punct\n",
    "    text = re.sub('[^A-z0-9]', ' ', text)\n",
    "    #remove extras whitespaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_similar_words(nouns, aspects):\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "\taspect_classes = {k: list() for k in aspects}\n",
    "\tfor noun in nouns:\n",
    "\t\tscores = list()\n",
    "\t\tfor aspect in aspects:\n",
    "\t\t\taspect_token = nlp(aspect)\n",
    "\t\t\tnoun_token = nlp(noun)\n",
    "\t\t\tsimilarity_score = aspect_token.similarity(noun_token)\n",
    "\t\t\tscores.append(similarity_score)\n",
    "\t\tindex = scores.index(max(scores))\n",
    "\t\taspect_name = aspects[index]\n",
    "\t\t\n",
    "\t\tif max(scores)>0.60:\n",
    "\t\t\tvalue = aspect_classes[aspect_name]\n",
    "\t\t\tvalue.append(noun)\n",
    "\t\t\taspect_classes[aspect_name] = list(set(value))\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\treturn aspect_classes\t\n",
    "\n",
    "\n",
    "def get_sentiment(aspect_classes, text):\n",
    "  sentiment_dict = {k:0 for k in aspect_classes}\n",
    "  for aspect in aspect_classes:\n",
    "    alt_names = aspect_classes[aspect]\n",
    "    for name in alt_names:\n",
    "      question = f'how is {name}'\n",
    "      QA_input = {'question': question, 'context': text}\n",
    "      qa_result = qa_model(QA_input)\n",
    "      answer = qa_result['answer']\n",
    "\n",
    "      #sentiment model \n",
    "      sent_result = sent_model(answer)    \n",
    "      print(sent_result)\n",
    "      sentiment = sent_result[0]['label']\n",
    "\n",
    "      if sentiment == 'LABEL_0':\n",
    "        sentiment, score = 'Negative', -1\n",
    "      elif sentiment == 'LABEL_1':\n",
    "        sentiment, score = 'Neutral', 0\n",
    "      else:\n",
    "        sentiment, score = 'Positive', 1\n",
    "    \n",
    "      value = sentiment_dict[aspect] + score\n",
    "      sentiment_dict[aspect] = value\n",
    "  return sentiment_dict\n",
    "  qa_tokenizer = AutoTokenizer.from_pretrained(\"./models/qa_model\")\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"./models/qa_model\")\n",
    "qa_model = pipeline('question-answering', model=qa_model, tokenizer=qa_tokenizer)\n",
    "\n",
    "sent_tokenizer = AutoTokenizer.from_pretrained(\"./models/sentiment_model\")\n",
    "sent_model = AutoModelForSequenceClassification.from_pretrained(\"./models/sentiment_model\")\n",
    "sent_model = pipeline('text-classification', model=sent_model, tokenizer=sent_tokenizer)\n",
    "\n",
    "def compute(text, aspects, qa_model, sent_model):\n",
    "\t#preprocessing\n",
    "\tpreprocess_text = preprocess(text)\n",
    "\t#get nouns\n",
    "\tnoun_list = get_noun(preprocess_text)\t\n",
    "\t#get alternative names of aspects\n",
    "\taspect_classes = get_similar_words(noun_list, aspects)\n",
    "\t#get sentiment\n",
    "\tsentiment_result = get_sentiment(aspect_classes, text, qa_model, sent_model)\n",
    "\treturn sentiment_result\n",
    "\n",
    "\n",
    "\n",
    "def aspect_sentiment(aspects, hashtag):\n",
    "\t# request_content = requests.get_json()\n",
    "\t# aspects = request_content.get('aspects', None)\n",
    "\t# hashtag = request_content.get('hashtag', None)\n",
    "\n",
    "\tif not aspects or aspects == list() :\n",
    "\t\treturn {'statusCode': 400, 'body': 'aspects not found in request'}\n",
    "\n",
    "\tif not hashtag or hashtag.strip() == '':\n",
    "\t\treturn {'statusCode': 400, 'body': 'hashtag not found in request'}\n",
    "\n",
    "\t#extracts 50 tweets regarding the hashtag from twitter\n",
    "\ttwitter_content = get_tweets(hashtag, consumer_key, consumer_secret, access_token, access_token_secret, tweet_count=50)\n",
    "\taspect_score = {asp : {'positive': 0, 'negative': 0} for asp in aspects}\n",
    "\t\n",
    "\t#compute scores for each tweet\n",
    "\tif twitter_content.to_dict():\n",
    "\t\tfor text in twitter_content['text']:\n",
    "\t\t\tsentiment_result = compute(text, aspects, qa_model, sent_model)\n",
    "\t\t\tfor result in sentiment_result:\n",
    "\t\t\t\tscore = sentiment_result[result]\n",
    "\t\t\t\tif score>0:\n",
    "\t\t\t\t\taspect_score[result]['positive'] = aspect_score[result]['positive'] + score\n",
    "\t\t\t\telif score<0:\n",
    "\t\t\t\t\taspect_score[result]['negative'] = aspect_score[result]['negative'] - score\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpass\n",
    "\telse:\n",
    "\t\treturn {'statusCode': 400, 'body': 'No twitter data scraped for this hashtag'}\n",
    "\n",
    "\n",
    "\n",
    "\tresult_list = [[k, 'positive', v['positive']] for k,v in aspect_score.items()]\n",
    "\tresult_list.extend([[k, 'negative', v['negative']] for k,v in aspect_score.items()])\n",
    "\n",
    "\t#plot the bar plot across all aspects\n",
    "\taspects_df = pd.DataFrame(result_list, columns= ['aspect', 'sentiment', 'score'])\n",
    "\tsns.barplot(x = 'aspect', y = 'score', hue='sentiment', data=aspects_df)\n",
    "\tplt.savefig('result.png')\n",
    "\n",
    "\t#send base64 string of image as response\n",
    "\timg_result = None\n",
    "\twith open('result.png', 'rb') as f:\n",
    "\t\tim_b64 = base64.b64encode(f.read())\n",
    "\t\timg_result = str(im_b64)\n",
    "\tif img_result:\n",
    "\t\treturn {'statusCode': 200, 'body': json.dumps(img_result)}\n",
    "\telse:\n",
    "\t\treturn {'statusCode': 400, 'body': 'issue in saving result image'}\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
